transformers==4.28.0
torch>=1.10.0
datasets>=2.0.0
accelerate>=0.9.0
# If you want to use a specialized library for PPO (e.g. huggingface/trl),
# you could include it here. We'll show a minimal manual PPO approach instead.
